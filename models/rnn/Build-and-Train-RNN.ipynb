{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "This implements a simple, naive sequence-to-sequence RNN for machine translation. There will be no LSTM units or GRU units here - this is a bare-bones RNN implementation (just some hidden state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils import load_en_fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing english...\n",
      "[1/3] preprocessing\n",
      "[2/3] building vocab\n",
      "[3/3] processing\n",
      "processing french...\n",
      "[1/3] preprocessing\n",
      "[2/3] building vocab\n",
      "[3/3] processing\n",
      "Processing took: 0.01m\n"
     ]
    }
   ],
   "source": [
    "dataset, EN, FR = load_en_fr(root='../..', mini=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_portion = 0.9\n",
    "train_len = math.floor(train_portion * len(dataset))\n",
    "valid_len = len(dataset) - train_len\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_len, valid_len])\n",
    "\n",
    "(len(train_dataset), len(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This encoder is modeled to be similar to the encoder\n",
    "# described in the PyTorch tutorial:\n",
    "# https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, field, embedding_size, hidden_size, dropout_param):\n",
    "        super().__init__()\n",
    "\n",
    "        vocab = field.vocab\n",
    "        pad_idx = vocab.stoi[field.pad_token]\n",
    "\n",
    "        self.input_size = len(vocab.stoi)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = len(vocab.stoi)\n",
    "        self.dropout_param = dropout_param\n",
    "        \n",
    "        self.i2e = torch.nn.Embedding(self.input_size, embedding_size, padding_idx=pad_idx)\n",
    "        self.e2h = torch.nn.Linear(embedding_size + hidden_size, hidden_size)\n",
    "        self.e2o = torch.nn.Linear(embedding_size + hidden_size, self.output_size)\n",
    "        self.oh2o = torch.nn.Linear(self.output_size + hidden_size, self.output_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout_param)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden_prev):\n",
    "        X = self.i2e(input)\n",
    "        X = torch.cat([X, hidden_prev], dim=1)\n",
    "        hidden = self.e2h(X)\n",
    "        output = self.e2o(X)\n",
    "        output = torch.cat([output, hidden], dim=1)\n",
    "        output = self.oh2o(output)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        return self.softmax(output), hidden\n",
    "\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # TODO: Not sure if this is the correct way to generalize\n",
    "        # the hidden input to a large batch size. It feels like the\n",
    "        # proper way may be to just concatenate <batch_size> copies of\n",
    "        # the same hidden representation as columns.\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Decoder is modeled to look the similar to the encoder.\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, field, embedding_size, hidden_size, dropout_param):\n",
    "        super().__init__()\n",
    "        \n",
    "        vocab = field.vocab\n",
    "        pad_idx = vocab.stoi[field.pad_token]\n",
    "\n",
    "        self.input_size = len(vocab.stoi)\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = len(vocab.stoi)\n",
    "        self.dropout_param = dropout_param\n",
    "        \n",
    "        self.i2e = torch.nn.Embedding(self.input_size, embedding_size, padding_idx=pad_idx)\n",
    "        self.e2h = torch.nn.Linear(embedding_size + hidden_size, hidden_size)\n",
    "        self.e2o = torch.nn.Linear(embedding_size + hidden_size, self.output_size)\n",
    "        self.oh2o = torch.nn.Linear(self.output_size + hidden_size, self.output_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout_param)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, hidden_prev):\n",
    "        X = self.i2e(input)\n",
    "        X = torch.cat([X, hidden_prev], dim=1)\n",
    "        hidden = self.e2h(X)\n",
    "        output = self.e2o(X)\n",
    "        output = torch.cat([output, hidden], dim=1)\n",
    "        output = self.oh2o(output)\n",
    "        output = self.dropout(output)\n",
    "\n",
    "        return self.softmax(output), hidden\n",
    "\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        # TODO: Not sure if this is the correct way to generalize\n",
    "        # the hidden input to a large batch size. It feels like the\n",
    "        # proper way may be to just concatenate <batch_size> copies of\n",
    "        # the same hidden representation as columns.\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "Epoch 158, Batch 1\n",
      "Loss: 1338.5963134765625\n",
      "Epoch 158, Batch 2\n",
      "Loss: 907.57470703125\n",
      "Epoch 158, Batch 3\n",
      "Loss: 12118.4052734375\n",
      "Epoch 158, Batch 4\n",
      "Loss: 610.9775390625\n",
      "Epoch 158, Batch 5\n",
      "Loss: 1047.3250732421875\n",
      "Epoch 158, Batch 6\n",
      "Loss: 1100.5404052734375\n",
      "Epoch 158, Batch 7\n",
      "Loss: 1288.9718017578125\n",
      "Epoch 158, Batch 8\n",
      "Loss: 2719368.75\n",
      "Epoch 158, Batch 9\n",
      "Loss: 1649.4808349609375\n",
      "Epoch 158, Batch 10\n",
      "Loss: 153870206500864.0\n",
      "Epoch 158, Batch 11\n",
      "Loss: 1310.01904296875\n",
      "Epoch 158, Batch 12\n",
      "Loss: 934136663506944.0\n",
      "Epoch 158, Batch 13\n",
      "Loss: 1482.5887451171875\n",
      "Epoch 158, Batch 14\n",
      "Loss: 2607.7294921875\n",
      "Epoch 158, Batch 15\n",
      "Loss: 2715.912841796875\n",
      "Epoch 158, Batch 16\n",
      "Loss: 2983.06005859375\n",
      "Epoch 158, Batch 17\n",
      "Loss: 3480.14501953125\n",
      "Epoch 158, Batch 18\n",
      "Loss: 535929.75\n",
      "Epoch 158, Batch 19\n",
      "Loss: 14988157952.0\n",
      "Epoch 158, Batch 20\n",
      "Loss: 139698274041856.0\n",
      "Epoch 158, Batch 21\n",
      "Loss: 5469.02197265625\n",
      "Epoch 158, Batch 22\n",
      "Loss: 1436717809664.0\n",
      "Epoch 158, Batch 23\n",
      "Loss: 1.897858004708806e+19\n",
      "Epoch 158, Batch 24\n",
      "Loss: 27085530.0\n",
      "Epoch 158, Batch 25\n",
      "Loss: 4.899902320830264e+21\n",
      "Epoch 158, Batch 26\n",
      "Loss: 1.3962729475218583e+21\n",
      "Epoch 158, Batch 27\n",
      "Loss: 8.137460576265993e+20\n",
      "Epoch 158, Batch 28\n",
      "Loss: 2.5453588629898134e+20\n",
      "Epoch 158, Batch 29\n",
      "Loss: 5.820912633883342e+19\n",
      "Epoch 2 / 10\n",
      "Epoch 158, Batch 1\n",
      "Loss: 2.1375961797360615e+19\n",
      "Epoch 158, Batch 2\n",
      "Loss: 7.807932235511759e+18\n",
      "Epoch 158, Batch 3\n",
      "Loss: 2.644924423760511e+18\n",
      "Epoch 158, Batch 4\n",
      "Loss: 2.165431663494955e+18\n",
      "Epoch 158, Batch 5\n",
      "Loss: 8.534923963678065e+17\n",
      "Epoch 158, Batch 6\n",
      "Loss: 8.371763997258547e+17\n",
      "Epoch 158, Batch 7\n",
      "Loss: 4.5998151411381043e+18\n",
      "Epoch 158, Batch 8\n",
      "Loss: 1.0876090845518365e+19\n",
      "Epoch 158, Batch 9\n",
      "Loss: 7.117451440213197e+16\n",
      "Epoch 158, Batch 10\n",
      "Loss: 1.1134994772656128e+16\n",
      "Epoch 158, Batch 11\n",
      "Loss: 3185695355043840.0\n",
      "Epoch 158, Batch 12\n",
      "Loss: 1619809066287104.0\n",
      "Epoch 158, Batch 13\n",
      "Loss: 661886941003776.0\n",
      "Epoch 158, Batch 14\n",
      "Loss: 305791437373440.0\n",
      "Epoch 158, Batch 15\n",
      "Loss: 153821653237760.0\n",
      "Epoch 158, Batch 16\n",
      "Loss: 73606780420096.0\n",
      "Epoch 158, Batch 17\n",
      "Loss: 37726153867264.0\n",
      "Epoch 158, Batch 18\n",
      "Loss: 18845108535296.0\n",
      "Epoch 158, Batch 19\n",
      "Loss: 12051645726720.0\n",
      "Epoch 158, Batch 20\n",
      "Loss: 7307931942912.0\n",
      "Epoch 158, Batch 21\n",
      "Loss: 4508186312704.0\n",
      "Epoch 158, Batch 22\n",
      "Loss: 2644649967616.0\n",
      "Epoch 158, Batch 23\n",
      "Loss: 2099520995328.0\n",
      "Epoch 158, Batch 24\n",
      "Loss: 1605901877248.0\n",
      "Epoch 158, Batch 25\n",
      "Loss: 1668989190144.0\n",
      "Epoch 158, Batch 26\n",
      "Loss: 768768868352.0\n",
      "Epoch 158, Batch 27\n",
      "Loss: 724447592448.0\n",
      "Epoch 158, Batch 28\n",
      "Loss: 742754811904.0\n",
      "Epoch 158, Batch 29\n",
      "Loss: 346717978624.0\n",
      "Epoch 3 / 10\n",
      "Epoch 158, Batch 1\n",
      "Loss: 448445579264.0\n",
      "Epoch 158, Batch 2\n",
      "Loss: 309983707136.0\n",
      "Epoch 158, Batch 3\n",
      "Loss: 272113844224.0\n",
      "Epoch 158, Batch 4\n",
      "Loss: 306399248384.0\n",
      "Epoch 158, Batch 5\n",
      "Loss: 299303075840.0\n",
      "Epoch 158, Batch 6\n",
      "Loss: 294829391872.0\n",
      "Epoch 158, Batch 7\n",
      "Loss: 240084549632.0\n",
      "Epoch 158, Batch 8\n",
      "Loss: 202544398336.0\n",
      "Epoch 158, Batch 9\n",
      "Loss: 198894714880.0\n",
      "Epoch 158, Batch 10\n",
      "Loss: 201911713792.0\n",
      "Epoch 158, Batch 11\n",
      "Loss: 196247470080.0\n",
      "Epoch 158, Batch 12\n",
      "Loss: 217419546624.0\n",
      "Epoch 158, Batch 13\n",
      "Loss: 195631988736.0\n",
      "Epoch 158, Batch 14\n",
      "Loss: 209780342784.0\n",
      "Epoch 158, Batch 15\n",
      "Loss: 214489825280.0\n",
      "Epoch 158, Batch 16\n",
      "Loss: 175130542080.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c64f65e4f830>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Step 3: Back-Propagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init_token_idx = FR.vocab.stoi[FR.init_token]\n",
    "\n",
    "batch_size = 32\n",
    "data_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "\n",
    "encoder = Encoder(EN, embedding_size=100, hidden_size=100, dropout_param=0.1)\n",
    "decoder = Decoder(FR, embedding_size=100, hidden_size=100, dropout_param=0.1)\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(f'Epoch {i+1} / {epochs}')\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for j, samples in enumerate(data_loader):\n",
    "        loss = 0\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        # Step 1: Feed data through encoder.\n",
    "\n",
    "        en_samples = samples[0]\n",
    "        encoder_input_len = en_samples.size()[1]\n",
    "\n",
    "        encoder_hidden = encoder.init_hidden(len(en_samples))\n",
    "\n",
    "        for k in range(encoder_input_len):\n",
    "            input = en_samples[:, k]\n",
    "            output, encoder_hidden = encoder(input, encoder_hidden)\n",
    "\n",
    "        # Step 2: Feed data through decoder.\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        # TODO: For now, only doing teacher forcing. Need to update this.\n",
    "        fr_samples = samples[1]\n",
    "        decoder_input_len = fr_samples.size()[1]\n",
    "        \n",
    "        for k in range(decoder_input_len - 1):\n",
    "            input = fr_samples[:, k]\n",
    "            output, decoder_hidden = decoder(input, decoder_hidden)\n",
    "            expected = fr_samples[:, k+1]\n",
    "            loss += criterion(output, expected)\n",
    "            \n",
    "        # Step 3: Back-Propagate\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {i+1}, Batch {j+1}')\n",
    "        print(f'Loss: {loss.item()}')\n",
    "\n",
    "    print(f'Finished epoch {i+1}. Loss={epoch_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
